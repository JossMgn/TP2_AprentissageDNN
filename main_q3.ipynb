{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":74865,"databundleVersionId":8192339,"sourceType":"competition"},{"sourceId":3221159,"sourceType":"datasetVersion","datasetId":1953623}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T05:13:47.643597Z","iopub.execute_input":"2024-04-21T05:13:47.643953Z","iopub.status.idle":"2024-04-21T05:13:48.004282Z","shell.execute_reply.started":"2024-04-21T05:13:47.643922Z","shell.execute_reply":"2024-04-21T05:13:48.003357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install poutyne\n!pip install git+https://github.com/ulaval-damas/glo4030-labs.git","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:13:48.160065Z","iopub.execute_input":"2024-04-21T05:13:48.161051Z","iopub.status.idle":"2024-04-21T05:14:20.599540Z","shell.execute_reply.started":"2024-04-21T05:13:48.161014Z","shell.execute_reply":"2024-04-21T05:14:20.598489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport torch.optim as optim\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nimport poutyne as pt\nfrom deeplib.history import History\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import v2","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:14:20.601994Z","iopub.execute_input":"2024-04-21T05:14:20.602397Z","iopub.status.idle":"2024-04-21T05:14:39.019680Z","shell.execute_reply.started":"2024-04-21T05:14:20.602351Z","shell.execute_reply":"2024-04-21T05:14:39.018877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Définition des transformations pour les données à partir imageNet\ntransform1 = v2.Compose([\n    v2.Resize((224, 224)),\n    v2.ToImage(), \n    v2.ToDtype(torch.float32, scale=True),\n    \n    v2.RandomVerticalFlip(0.5),\n    v2.ColorJitter(),\n    v2.GaussianBlur(kernel_size=5),\n    \n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntest_transform = v2.Compose([\n    v2.Resize((224, 224)),\n    v2.ToImage(), \n    v2.ToDtype(torch.float32, scale=True),\n    \n    \n    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:14:39.021138Z","iopub.execute_input":"2024-04-21T05:14:39.022229Z","iopub.status.idle":"2024-04-21T05:14:39.030120Z","shell.execute_reply.started":"2024-04-21T05:14:39.022189Z","shell.execute_reply":"2024-04-21T05:14:39.029080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_len = 40\ntransform = transform1\n\ndataset = torchvision.datasets.ImageFolder('/kaggle/input/glo-7030-ou-suis-je-h2024/train', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:14:39.032683Z","iopub.execute_input":"2024-04-21T05:14:39.033449Z","iopub.status.idle":"2024-04-21T05:14:46.449623Z","shell.execute_reply.started":"2024-04-21T05:14:39.033414Z","shell.execute_reply":"2024-04-21T05:14:46.448649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a,b = dataset[-1]\n\nprint(len(dataset))\nprint(b)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:14:46.450928Z","iopub.execute_input":"2024-04-21T05:14:46.451228Z","iopub.status.idle":"2024-04-21T05:14:46.584253Z","shell.execute_reply.started":"2024-04-21T05:14:46.451202Z","shell.execute_reply":"2024-04-21T05:14:46.583269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# la classe ImageFolder assigne automatiquement un label pour chaque nom de classe (class -> idx)\nprint('class -> idx : ',dataset.class_to_idx)\n\n# on aura besoin d'un dictionnaire qui fait le sens inverse (idx -> class)\nidx_to_class = {dataset.class_to_idx[class_name]: class_name for class_name in  dataset.class_to_idx}\nprint('idx -> class : ',idx_to_class)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:14:46.585673Z","iopub.execute_input":"2024-04-21T05:14:46.586191Z","iopub.status.idle":"2024-04-21T05:14:46.591304Z","shell.execute_reply.started":"2024-04-21T05:14:46.586163Z","shell.execute_reply":"2024-04-21T05:14:46.590305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_SIZE = 0.9\ntrain_set, valid_set = random_split(dataset, [TRAIN_SIZE, 1-TRAIN_SIZE])\n\n# train_set.transform = transform1\n# valid_set.transform = test_transform\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_len, shuffle=True)#,collate_fn=collate_fn)\nvalid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_len, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:16:24.128554Z","iopub.execute_input":"2024-04-21T05:16:24.129216Z","iopub.status.idle":"2024-04-21T05:16:24.136295Z","shell.execute_reply.started":"2024-04-21T05:16:24.129185Z","shell.execute_reply":"2024-04-21T05:16:24.135374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_set))\nprint(len(valid_set))\nprint(len(dataset) , \" et :\", len(train_set)+len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:16:24.843199Z","iopub.execute_input":"2024-04-21T05:16:24.843927Z","iopub.status.idle":"2024-04-21T05:16:24.849337Z","shell.execute_reply.started":"2024-04-21T05:16:24.843893Z","shell.execute_reply":"2024-04-21T05:16:24.848263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EFA_Net(nn.Module):\n  def __init__(self, NUM_CLASSES):\n    super().__init__()\n\n    model = models.efficientnet_v2_l(weights=\"DEFAULT\")\n    model.classifier[-1] = nn.Linear(in_features=model.classifier[-1].in_features, out_features= NUM_CLASSES, bias = True)\n\n#     for name, param in model.named_parameters():\n#       print(name)\n\n    # print(model)\n    \n    for n,p in model.named_parameters():\n      if 'classifier' not in n and 'features.8' not in n and 'features.7.6' not in n and 'features.7.5' not in n:\n            \n        p.requires_grad = False\n      else :\n        print(n)\n\n    self.model = model\n\n  def forward(self, x):\n    return self.model(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:16:25.645416Z","iopub.execute_input":"2024-04-21T05:16:25.645778Z","iopub.status.idle":"2024-04-21T05:16:25.652975Z","shell.execute_reply.started":"2024-04-21T05:16:25.645749Z","shell.execute_reply":"2024-04-21T05:16:25.651908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Paramètres\nNUM_CLASSES = 5\nN_EPOCHS = 100\nTRAIN_SIZE = 0.8\nUSE_GPU = True\n\nlr = 0.1#0.006\n\n#Initialisations\nnet = EFA_Net(NUM_CLASSES)\n\n# optimizer = optim.SGD(net.parameters(), lr=lr)\n# optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=1e-3, nesterov=True, momentum=0.9)\noptimizer = optim.Adam(net.parameters(), lr=lr)\n\nloss = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:16:26.782103Z","iopub.execute_input":"2024-04-21T05:16:26.782491Z","iopub.status.idle":"2024-04-21T05:16:29.414291Z","shell.execute_reply.started":"2024-04-21T05:16:26.782460Z","shell.execute_reply":"2024-04-21T05:16:29.413333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On crée un objet Model de Poutyne avec la fonction de perte et les métriques souhaitées.\nmodel = pt.Model(net, optimizer, 'cross_entropy', batch_metrics=['accuracy'])\nmodel.cuda()\n\n# Comme dit précedemment, on utilise la méthode `fit_generator` pour procéder à l'entraînement.\np=7\n\nscheduler = pt.ReduceLROnPlateau(monitor='val_acc', mode='max', patience=3, factor=0.5, verbose=True)\n\n# Early stopping sous la forme d'un Callback\nearly_stopping = pt.EarlyStopping(monitor='val_acc', mode='max', min_delta=1e-5, patience=p, verbose=True)\n\n# history = train(net, optimizer, cifar_train, n_epoch=40, batch_size=64, callbacks=[scheduler, early_stopping], use_gpu=True)\n\nhistory = model.fit_generator(train_loader, valid_loader, epochs=N_EPOCHS, callbacks=[scheduler, early_stopping])\n\n# La classe History peut aussi prendre un historique de Poutyne en entrée.\nHistory(history).display()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T05:16:29.416192Z","iopub.execute_input":"2024-04-21T05:16:29.417043Z","iopub.status.idle":"2024-04-21T05:16:30.347205Z","shell.execute_reply.started":"2024-04-21T05:16:29.417007Z","shell.execute_reply":"2024-04-21T05:16:30.345881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on hérite de la classe Dataset de PyTorch \nclass TestDataset(Dataset):\n    def __init__(self, test_path, transform=None):\n        \n        # lister toutes les images dans le repertoire test\n        # self.image_paths va etre une liste contenant des \n        # elements de type Path (pour plus d'info voir la class Path de pathlib)\n        # cela fonctionne seulement pour les versions de python >3.4\n        self.image_paths = list(pathlib.Path(test_path).glob('*.jpg'))\n        \n        # trier les noms des fichiers d'images par ordre\n        self.image_paths.sort()\n        \n        # garder la fonctions de tranform dans self pour l'utiliser dans __getitem__\n        self.transform = transform\n\n    def __getitem__(self, index):\n        # index est un nombre qui vient du dataloader (il est entre 0 et ce que retourne la methode __len__ ci-dessous)\n        # c'est donc entre 0 et le nombre d'images de test\n        img_path = self.image_paths[index]\n        \n        # retourner aussi le nom de l'image en question(i.e. '0xxxx')\n        # sans l'extension '.jpg', donc on ignore les 4 dernier caracteres du nom de l'image (.jpg) avec [:-4]\n        # par exemple, pour l'image '00037.jpg' on retourne '00037'\n        # cela va vous etre util pour generer le fichier predictions.csv\n        img_name = img_path.name[:-4] #img_path est un objet de type Path, et a donc un attribut 'name'\n        \n        # lire l'image avec PIL\n        img = Image.open(img_path)\n        \n        # appliquer les transforms s'il y'en a\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, img_name\n\n    def __len__(self):\n        return len(self.image_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# nous utilisons pathlib afin de parcourir les dossiers et fichiers\nimport pathlib\nfrom PIL import Image ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nous allons tester la classe TestDataset\ntest_dataset = TestDataset('/kaggle/input/glo-7030-ou-suis-je-h2024/test', transform=test_transform) # ici je transforme les images en Tensor pour une utilisation rapide de PyTorch Dataloader \n\n# on aura besoin d'un dataloader qui enveloppe notre objet test_dataset\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4) # souvent le shuffle est mis a False, mais avec notre implementation, ca marche dans tous les cas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generons une prediction aleatoire pour notre test\nlabel_predictions = []\nimage_names = []\nfor batch,im_names in test_loader:\n    # remplir avec des predictions aleatoires (entre 0 et 4)\n    random_preds = model.predict(batch,verbose=False)\n#     print(random_preds)\n    _, preds = torch.max(torch.Tensor(random_preds), 1)\n#     preds = m(torch.Tensor(random_preds))\n#     print(preds)\n    label_predictions.extend(preds) \n    \n    # retenir les noms des images\n    image_names.extend(im_names) \n\nassert len(label_predictions) == len(image_names) \nassert len(label_predictions) == len(test_dataset) # est-ce qu'on a prédits tous les exemples de tests ?\nprint(f'Il y a {len(label_predictions)} exemples de test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utilisons Pandas afin de generer un DataFrame\n\npredictions_df = pd.DataFrame(data=zip(image_names, label_predictions), columns=['image_name', 'class_label'])\npredictions_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df['class_label']=predictions_df['class_label'].apply(lambda x : int(x))\npredictions_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df['class']=predictions_df['class_label'].apply(lambda x : idx_to_class[x])\npredictions_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on drop la colonne class_label avant d'entregistrer en fichier CSV\npredictions_df = predictions_df.drop(labels=['class_label'], axis=1)\npredictions_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enregistrer dans fichier de format CSV\n# N'OUBLIEZ PAS DE METTRE index=None\npredictions_df.to_csv('./mes_predictions.csv', index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}